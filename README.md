# Learning

This repo is a non-exhaustive annotated bibliography of resources I have used for learning. Materials primarily cover mathematics, computer science, statistics, and machine learning. I am interested in understanding how autonomous, inferential agents are built, so most entries are somehow related to that aim. I hope to add more perspectives from neuroscience and biology as I progress. I am also interested in urban planning, . Many of these resources may be best consumed in parallel with other resources in this list.

Where resources can be purchased or viewed for free, links are provided, though these links are not necessarily the "best" way to acquire many of these items. When a material is marked with a checkmark ("✓"), that means I have "completed" it (at least one read-through). However, many of these resources, especially the textbooks, are best utilized as a recurring source of review and learning.

## Books

|Title|Author(s)|Completion Status|Review|Pre-reqs|
|---|---|---|---|---|
|[Trig without Tears or, How to Remember Trigonometric Identities](https://brownmath.com/twt/index.htm)|Brown|✓|This book is about 75 pages and can be mastered within a week, giving a broader perspective on trigonometry that makes it far easier to apply throughout the rest of mathematics. |basic algebra|
|Trigonometric Delights|Eli Maor|Not started|I have read that anything written by Eli Maor is worth reading.|...|
|[Discrete Mathematics and Its Applications](https://www.amazon.com/Discrete-Mathematics-Applications-Kenneth-Rosen/dp/125967651X)|Rosen|✓|This is the first mathematics textbook I properly read. It is engaging and provides an excellent introduction to proofs and a smattering of subjects that will be helpful to budding computer scientists. |High school algebra, novice programming ability|
|[Introduction to the Theory of Computation](https://www.amazon.com/Introduction-Theory-Computation-Michael-Sipser/dp/113318779X)|Sipser|✓|The canonical introduction to computer science theory. I first read this book in my undergraduate theory of computation course, and have found myself returning to it for refreshers since. |Discrete Mathematics, Calculus, some programming helpful|
|[Introduction to Algorithms](https://www.amazon.com/Introduction-Algorithms-3rd-MIT-Press/dp/0262033844)|Cormen, Leiserson, Rivest, & Stein (CLRS)|✓|The most comprehensive formal book on computer algorithms out there. In my experience, this is not a book not grasped all at once. I have found it to be an excellent reference and source of review, though.|Discrete Mathematics, Calculus, intermediate programming ability|
|[https://www.amazon.com/Operating-Systems-Principles-Thomas-Anderson/dp/0985673524](https://www.amazon.com/Operating-Systems-Principles-Thomas-Anderson/dp/0985673524)|Anderson|✓|This textbook was a deeply enjoyable read and helped me excel in my operating systems class. The book gives just enough guidance to make the subject tractable, but not too much to make it easy.| Data Structures & Algorithms and novice understanding of operating systems.|
|[Effective Modern C++](https://www.amazon.com/Effective-Modern-Specific-Ways-Improve/dp/1491903996)|Meyers|In Progress|The C++ developer's gospel. I started reading this book when I was writing C++ code in college. It helped me improve the quality and organization of my code dramatically, sped up development time, and gave me a deep appreciation for C++ as a language (as goofy as it is). I will definitely be returning to this book if I ever get the chance to write C++ in my career again.|Significant exposure to C++ and a solid understanding of programming languages|
|[Deep Learning](https://www.amazon.com/Deep-Learning-Foundations-Christopher-Bishop/dp/3031454677/ref=asc_df_3031454677/?tag=hyprod-20&linkCode=df0&hvadid=693348626821&hvpos=&hvnetw=g&hvrand=7436683566412610138&hvpone=&hvptwo=&hvqmt=&hvdev=c&hvdvcmdl=&hvlocint=&hvlocphy=9016996&hvtargid=pla-2205744745915&psc=1&mcid=a92c257ef7a03f2bb369f7da7818a295&gad_source=1&gclid=Cj0KCQjwltKxBhDMARIsAG8KnqXjK2LpQYZEkQz2O4xN0hcQPq7hjsbmdSWJHbS68cMx3_aha8VFbjIaAplPEALw_wcB)|Bishop & Bishop|In Progress|As of May 2024, this is the best introduction to deep learning that I have read. Its first two chapters serve as great resources for reviewing probability and information theory. For those interested in diving straight into deep learning, I would recommend this book over e.g. the much recommended Elements of Statistical Learning.|Calculus, linear algebra, probability theory, novice programming ability|
|[Active Inference](https://mitpress.mit.edu/9780262045353/active-inference/)|Parr, Frezullo, Friston|In progress|Excellent book that dives into Friston's "Active Inference", a theory of how intelligent agents update their beliefs with an upper-bounded approximation to ideal Bayesian reasoning. I cannot recommend this book enough. |Probability Theory, Calculus, Information Theory. This book also benefits from neuroscience, physics, and machine learning perspectives.|
|[Machine Learning: A Probablistic Perspective](https://www.amazon.com/Machine-Learning-Probabilistic-Perspective-Computation-ebook/dp/B08FZLD4J4/ref=sr_1_9?crid=28MC33Z239RDS&dib=eyJ2IjoiMSJ9.WDMLUSp1o5wuPmHydsawXnbVm7I68LXxHj5jm7YDZ8_xt1dN41f7U3fBAG_GprizEpas8jkd6caYGaEkWCMeLyhBk7A1FmEOrG_XyE3T3gh2KEiWzWyi8XUoVxe-cxtj6J3MVOxnEbZF4OqW1fbXJ3eDW814i3xAPa4BPF8btCUIQPEByHwazZbqq07d6bNNIhV47K60yEiHMQNCm-XdHew0_nUXEKWswASYIkGOfv4.3gCuTx7KpVZe2MztyEtQMF7NkiT06KIsO-_RZk2oEkc&dib_tag=se&keywords=Machine+Learning%3A+A+Probablistic+Perspective&qid=1715021661&s=books&sprefix=machine+learning+a+probablistic+perspective%2Cstripbooks%2C114&sr=1-9)|Murhpy|Not started|This book is in the mail. I intend to pair it with Tubingen's Probablistic ML lectures.|
|[Gödel, Escher, Bach: An Eternal Golden Braid](https://www.amazon.com/G%C3%B6del-Escher-Bach-Eternal-Golden/dp/0465026567)|Hofstatder|Not started|This is my next "train book." I have unfortunately been away from the city, so it has been a bit since I have ridden the train. Excited to start commuting again!|Some computational theory may make this a more enjoyable read.|
|[Real Analysis: A Long Form Introduction](https://www.amazon.com/Real-Analysis-Long-Form-Mathematics-Textbook/dp/1077254547/ref=sr_1_31_sspa?crid=SO759J0Y5Z3H&dib=eyJ2IjoiMSJ9.8H96S-vpjIYx8lnvl5zYmJTzkEIinApCsJ9wsZQvKVDkb30vjQ_sJUN3uoo0TR2fGlx7X0eN9gNE7R6xjPd_X1obxDXlNq9xn3YOt-zfksQ3e2n8OtjmGVqh-uXhX5oWND0gWvnZfaXQTNAuOUYNyaoxXv_PRXvZQfFJaRItypNI21cFF-576dnPEgFHZbBQB9Vp3vnxBiQYpdTnAZHVo8yn8HiGQVjFKJPnv8AsxG93KEJ_MNA14SGwnZFzhHHawjHAhvzmd60uFt5IpUACKMU6qupI3nNwMeU3VkrDZzA.Ta8UR25ufichJlJxKqk5HUhkKoUo-kpX57SomXnPapw&dib_tag=se&keywords=Analysis&qid=1715022505&s=books&sprefix=analysis%2Cstripbooks%2C118&sr=1-31-spons&sp_csd=d2lkZ2V0TmFtZT1zcF9idGY&psc=1)|Cummings|In Progress|A fun, cheap introduction to analysis that I believe is excellent for the auto-didact. However, for the most extensive formal understanding of the subject, it should certainly be followed up on.|Calculus, diffeq, linear algebra, at least one proofs course|
|[Real Analysis: Modern  Techniques and their Applications](https://www.amazon.com/Real-Analysis-Long-Form-Mathematics-Textbook/dp/1077254547/ref=sr_1_31_sspa?crid=SO759J0Y5Z3H&dib=eyJ2IjoiMSJ9.8H96S-vpjIYx8lnvl5zYmJTzkEIinApCsJ9wsZQvKVDkb30vjQ_sJUN3uoo0TR2fGlx7X0eN9gNE7R6xjPd_X1obxDXlNq9xn3YOt-zfksQ3e2n8OtjmGVqh-uXhX5oWND0gWvnZfaXQTNAuOUYNyaoxXv_PRXvZQfFJaRItypNI21cFF-576dnPEgFHZbBQB9Vp3vnxBiQYpdTnAZHVo8yn8HiGQVjFKJPnv8AsxG93KEJ_MNA14SGwnZFzhHHawjHAhvzmd60uFt5IpUACKMU6qupI3nNwMeU3VkrDZzA.Ta8UR25ufichJlJxKqk5HUhkKoUo-kpX57SomXnPapw&dib_tag=se&keywords=Analysis&qid=1715022505&s=books&sprefix=analysis%2Cstripbooks%2C118&sr=1-31-spons&sp_csd=d2lkZ2V0TmFtZT1zcF9idGY&psc=1)|Folland|Not started|This came highly recommended from someone in the Active Inference Institute's discord.||

## Papers
The progress column for this section is filled out according to the [three pass approach](http://ccr.sigcomm.org/online/files/p83-keshavA.pdf) for reading academic papers. A checkmark indicates all three passes have been complete.

|Title|Author(s)|Completion Status|Review|Pre-reqs|
|---|---|---|---|---|
|[The Markov blankets of life: autonomy, active inference and the free energy principle](https://royalsocietypublishing.org/doi/10.1098/rsif.2017.0792)|Kirchoff, Friston, Whyte|✓|Among other things, this paper answers "the question of whether the Markov blanket formulation of biological systems is over-broad and thereby explanatorily empty with respect to autonomy" by introducing _adaptive active inference_. This addresses some concerns I have had regarding the seeming tautological nature of Active Inference. I regard it as essential reading for anyone looking to understand how Markov Blankets apply to agents within the Active Inference framework. |The first three chapters of Parr's _Active Inference_ book.|
|[A step-by-step tutorial on active inference and its application to empirical data](https://www.sciencedirect.com/science/article/pii/S0022249621000973)|Smith, Friston, Whyte|In Progress|||
|[Anomaly Detection via Controlled Sensing and Deep Active Inference](https://arxiv.org/pdf/2105.06288)|Joseph et al.|Second pass in progress|Put simply, I believe Active Inference's minimization of (variational) free energy can allow for flexible anomaly detection _and_ the flexible incorporation of anomalous information. For those unfamiliar with the field of anomaly detection, I think it may serve as an interesting perspective on active inference. I would recommend this paper for that alone. I have many more thoughts on the subject and may combine them into a blog post at some point.|Familiarity with active inference|
|[Tutorial on Variational Autoencoders](https://arxiv.org/abs/1606.05908)|Doersch|First pass|I am very interested in learning more about variational auto-encoders because of their reliance on variational inference. I have yet to find literature directly relating VAE's with Active Inference, though I have heard of conceptual linkages on Machine Learning Street Talk.|Some Deep Learning|
|[Bayesian surprise attracts human attention](https://www.sciencedirect.com/science/article/pii/S0042698908004380)|Itti, Baldi|First pass|This paper provides a fascinating perspective on the utility of surprise to active agents _instead of_ Shannon entropy, which is in my opinion not trivially apparent. This gives a simple and beautiful intuition behind why surprise is important.|N/A|
|[Reward Maximization Through Discrete Active Inference](https://direct.mit.edu/neco/article/35/5/807/115249/Reward-Maximization-Through-Discrete-Active)|Da Costa et al.|First pass|I really enjoyed the literature review of this paper, though I have not gotten much farther along in it. This is a fairly dense paper that contains many theoretically interesting proofs and comparisons to other forms of agential learning (e.g. Reinforcement Learning). I intend to review it further once I have completed further study in deep learning and reinforcement learning, which is currently in progress.|Reinforcement learning, deep learning, active inference.|
|[High-precision automated reconstruction of neurons with flood-filling networks
](https://www.nature.com/articles/s41592-018-0049-4)|Januszewski Et Al.|Not Started|I am keeping this paper here for reference later, in case I ever become more deeply involved in computational neuroscience.||
|[Dynamic Factor Graphs for Time Series Modeling](http://yann.lecun.com/exdb/publis/pdf/mirowski-ecml-09.pdf)|Mirowski & LeCun|First pass|I am reading papers on factor graphs and time series modelling to explore how Active Inference (often implemented with Factor Graphs) might be implemented in simple, idealized problem spaces, like exploring high dimensional time series data.||
|[Learned Factor Graphs for Inference from Stationary Time Series](https://arxiv.org/abs/2006.03258)|Shlezinger, Farsard, Eldar & Goldsmith|First pass|||
|[Core Knowledge](https://www.harvardlds.org/wp-content/uploads/2017/01/SpelkeKinzler07-1.pdf)|Spelke & Kinzler|First pass|This paper is somewhat foundational for those that are of the view that human-like AI will require "Core Knowledge," or knowledge that it has prior to training. This stands in contrast to those ||
|[Exploring complex networks](https://www.nature.com/articles/35065725)|Strogatz|Not started|Complex networks are much talked about in neuroscience and active inference; though I know little of them. This paper is supposed to be a great starting point.||
|[Random dynamical systems](https://www.researchgate.net/publication/270905136_Random_dynamical_systems)|Arnold, Crauel et al.|Not started|Random dynamical systems are also much talked of. This is meant to be a starting point, though I will likely have to move to a textbook for proper understanding eventually.||
|[Weak Markov Blankets in High-Dimensional Sparesely-coupled random dynamical systems](https://arxiv.org/abs/2207.07620)|Not started|These "weak" markov blankets are meant to allow for a relaxing of the constraints necessary to implement active inference. This is research apparently coming out of Verses, the AI lab trying to build active inference agents.||
|[Whatever next? Predictive brains, situated agents, and the future of cognitive science](https://pubmed.ncbi.nlm.nih.gov/23663408/)|Clark|Not started|A seminal paper that introduced much of the language used in modern Active Inference, to my understanding.||
|[Against digital ontology](https://philarchive.org/rec/FLOADO-2)|Floridi|An interesting philosophical piece that argues in favor of informational (structural) ontology in favor of digital ontology, thereby separating the world of computing as it has been known from the world as it actually exists.||
|[The Chinese Room Argument](https://plato.stanford.edu/entries/chinese-room/)|Not started|A nice overview of the Chinese room argument and various rebuttals and critiques.||
|[Minds, brains, and programs]()|Searle|The original paper that advanced the Chinese room argument, holds that digital computer programs cannot have minds or consciousness.||
|[Thinking through other minds: A variational approach to cognition and culture](https://pubmed.ncbi.nlm.nih.gov/31142395/)|Not started|A very interesting application of the free energy principal to social science research.||

## Online Coursework

|Course Name|Completion Status|Notes|Pre-reqs|
|---|---|---|---|
|[Andrew Ng's Deep Learning Specialization](https://www.coursera.org/specializations/deep-learning)|In progress|A straightforward set of videos and short, hand-holding ML projects that pairs well with machine learning textbooks by providing additional perspective, as well as practical coding skills for those unfamiliar with numpy/pandas.|Calculus, Probability, and co-requisite with a more theoretical approach to ML|
|[University of Pennsylvania, Calculus: Single Variable](https://www.coursera.org/learn/single-variable-calculus)|In progress|Excellent review of single variable calculus split into four short courses. Recommended for those that are seeking to review Calculus with a fresh perspective before continuing their mathematics education. Pairs well with a textbook or another source of practice problems. |Calculus I & II|
|https://www.fast.ai/|In progress|A good course, though my progress on it is stalled because my non-work laptop is having issues, and I am wary of downloading some of the files necessary for the course on my work laptop.|Python and intermediate coding ability.|
|[University of Tubingen - Probablistic ML](https://youtu.be/TTo2kjrAuTo?si=CWq132yI_BV3RtiD)|On lecture 4|The perfect graduate-level lecture series for probablistic ML for my level of understanding. For those that have not taken a theoretical probability course that emphasises a Bayesian perspective, I highly recommend this one. It is a blast.|Calculus, linear algebra, prior exposure to probability assumed.|
|[Stanford CS236: Deep Generative Models 2023](https://www.youtube.com/watch?v=XZ0PMRWXBEU)|On Lecture 4|Covers Auto-Regressive Models, Variational Auto-Encoders, Normalizing Flow Models, and Generative Adversarial Networks. Really helpful for understanding where conretizing some parts of Active Inference.|Introductory knowledge of machine learning and probability|
|[Khan Academy](https://www.khanacademy.org)|✓|I find myself returning to Khan Acadamy when I am doubting myself, having forgotten a relatively basic trick that I see come up in a later text. In my experience, it is not sufficient for learning a subject in depth, but it can provide quick review and practice for jogging your memory on how to perform certain calculations. The duolingo of mathematics, perhaps. I will also forever find comfort in Sal Kahn's voice.|N/A|
|[Classical Control Theory](https://www.youtube.com/watch?v=O-OqgFE9SD4&list=PLUMWjy5jgHK1NC52DXXrriwihVrYZKqjk&=2)|Brian Douglas|On Lecture 2|I know little of control theory, but this seems like a good introduction. I will likely pair it with a study of differential equations, and possibly then follow up with more formal explorations of control theory after that.|Calc I|

## Tutorials
TODO: add in Active Inference tutorials I have been working through.

## Videos
TODO

## Blogposts
TODO

## Articles
|[Generative and Discriminative Classifiers: Naive Bayes and Logistic Regression](https://www.cs.cmu.edu/~tom/mlbook/NBayesLogReg.pdf)||||

## Communities 
* [Active Inference Institute](https://www.activeinference.org/) - Join the discord! This is a great community with lots of helpful and incredibly smart members.

## Projects
TODO: Flesh this section out. To be honest I am sometimes concerned with the fact that anything I might invent is technically owned by Amazon--I believe this stifles innovation. Like the recent [FTC ban on non-competes](https://www.ftc.gov/news-events/news/press-releases/2024/04/ftc-announces-rule-banning-noncompetes), I would like to see this rule done away with. Some ideas I have, anyways:

## Possible Degree Programs
|University|Level|Program|Prerequisites|Application Deadline|
|---|---|---|---|---|
|Tubingen University|Masters|[Computational Neuroscience](https://uni-tuebingen.de/en/study/finding-a-course/degree-programs-available/detail/course/computational-neuroscience-master/#c311-language-requirements)|Profound knowledge in maths (linear algebra, analysis), statistics, elementary probability theory, and programming skills in at least one language are compulsory.|March 1st|

1. Good ol' cartpole and perhaps some other reinforcement learning problems.
2. Personal smart speaker using Claude 3 with some interesting tools for it to use. This is in progress, though tools need to be thought on more.
